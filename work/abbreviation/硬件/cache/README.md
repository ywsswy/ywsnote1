CPU要访问的数据在Cache中有缓存，称为“命中” (Hit)，反之则称为“缺失” (Miss)。
CPU访问它的速度介于寄存器（称为L0）与内存之间（数量级的差别）

CPU接收到指令后，它会按顺序查找一级缓存（L1 Cache）-> L2 Cache -> L3 Cache（通常为SRAM） -> 内存(通常为DRAM) -> 硬盘（ROM）

https://blog.csdn.net/hithj_cainiao/article/details/117354903

L3 Cache和L1，L2 Cache有着本质的区别。，L1和L2 Cache都是每个CPU core独立拥有一个，而L3 Cache是几个Cores共享的

Main memory（主存）是计算机系统中存储数据和指令的主要地方，RAM是主存的一种实现形式

DRAM（动态随机存取存储器）里面所储存的数据需要周期性地更新，比SRAM便宜；
SRAM（静态随机存取存储器-Static Random-Access Memory）是随机存取存储器的一种。所谓的“静态”，是指这种存储器只要保持通电，里面储存的数据就可以恒常保持，不需要刷新电路即能保存它内部存储的数据；

- cache一致性问题（跟编程语言中的并发一致性问题不同，数据量级可能不同，解决方案也不同，前者是在硬件上采用MESI等策略，后者是在程序中使用锁、信号量、原子操作、事务内存等同步机制来保证数据一致性）
多个处理器对某个内存块同时读写，会引起冲突的问题，这也被称为Cache一致性问题。
Cache一致性问题出现的原因是在一个多处理器系统中，多个处理器核心都能够独立地执行计算机指令，从而有可能同时对某个内存块进行读写操作，并且由于我们之前提到的回写和直写的Cache策略，导致一个内存块同时可能有多个备份，有的已经写回到内存中，有的在不同的处理器核心的一级、二级Cache中

- cache的局部性
程序在一段时间内访问的数据通常具有局部性，比如对一维数组来说，访问了地址x上的元素，那么以后访问地址x+1、x+2上元素的可能性就比较高；现在访问的数据，在不久之后再次被访问的可能性也比较高。局部性分为“时间局部性”和“空间局部性”