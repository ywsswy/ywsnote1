如果涉及到对get的数据做处理后再set时，
就存在并发问题；

一种简单方案是get的节点在之前尝试加锁setnx，处理完set之后再释放锁；

还有一种方案是数据中存储版本号（例如前四个字节），每次处理版本号要加一，set使用lua脚本进行set，脚本逻辑是get存储中的四个字节，判断是否等于当前传入的新值的版本号减一，是说明没有并发改动则写如数据，否则说明有其他线程已经set过了则应返回错误码，重新发起get和set操作；

当然逻辑简单的情况下也可以全程用lua脚本实现

lua脚本不是真的事务（不存在回滚等操作），
实现的原理是比较暴力的“伪”事务，就是一个lua执行的过程中，其他任何命令都不处理，显然并发性能很差;
Q：“锁定该命令涉及的key，还是锁定全部的key？锁定是锁定写还是锁定读？跟事务的关系？是保证要么全部成功要么全部失败，还是有可能部分成功？Lua 脚本在 Redis 中不支持跨分片（shard）或跨槽（slot）的事务？




腾讯云redis注意事项：
建议扩分片数，而不是扩一个节点的内存，因为在总内存相同的情况下（成本不变），分片数提高带宽吞吐量会提高；

带宽上限的计算公式是：分片数 * （附加带宽+标准带宽），标准带宽等于 “只读”副本数 * 768；
附加带宽在申请时默认当作是0，因此申请时带宽上限的计算公式是：分片数 * 只读副本数 * 768；
实际带宽上限的计算公式是：分片数 * (只读副本数 * 768 + 1536)
最后除以proxy节点数，就知道每个proxy最多放通多少流量了；

集群架构下proxy节点数的计算公式：https://cloud.tencent.com/document/product/239/51090
开启副本只读时：Proxy = Max[分片数 * 副本数（主不算）；分片数 * 1.5（向上取整）]
（如果非标调整了proxy节点数，多出来的这部分不参与后续调整的计算）

开启副本只读时：每个分片的最大连接数为 1W *（3+副本数（主不算）)，进而可以计算分摊到每个proxy节点上的限制为 （1+3/副本数（主不算））W，相当于副本越多，单个proxy节点限制的连接数越严格；
