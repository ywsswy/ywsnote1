利用经验改善系统自身的性能
研究学习算法
先是【数据（有了结果标记的）】通过【学习、训练】算法产生【模型、假设、学习器】（学得的结果），这样数据就能通过模型产生判断
模型（全局性结果）模式（局部性结果）
数据集》样本、示例、向量》属性、特征
属性空间、样本空间、输入空间
【监督学习
分类（离散）
回归（连续）
二分类（正类+反类）
【无监督学习
聚类	簇划分
归纳（从特殊事实总结出一般规律）
演绎（从一般原理演算出特殊结论）
递归（自身调用自身，条件控制结束）
迭代（循环，每次输入与上次循环有关，计数器控制结束）
归纳学习、概念学习
学习过程（在所有假设组成的空间中进行搜索的过程）
？三维向量，分别有4，3，2个属性取值，则此假设空间的规模为（5*4*3+1），多出的取值表示通配符？即无论什么都合适
假设空间（像分叉树，用各种策略搜索，不断删除非正例的假设，最后得到与训练集一致的假设（能正确判断所有训练样本的假设），即为学得的结果，可能为一个大的【版本空间】（包含多个假设）
归纳偏好（在多个假设中偏向拟合成哪个）
奥卡姆剃刀（选最简单的假设）
NFL（没有免费的午餐）定理，不同算法期望是相同的（脱离具体问题时，考虑所有潜在问题时，所有算法一样好）
丑小鸭定理，丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别 一样大，世界上不存在分类的客观标准，一切分类的标准都是主观的
大数定律，在随机事件的大量重复出现中，往往呈现几乎必然的规律，这个规律就是大数定律。
连接主义	神经网络	BP算法
符号主义	逻辑表示
统计学习	SVM支持向量机
