【线性回归（非线性即为高阶x^2)
1）
有监督（回归（值）、分类（））
样本（特征1，特征2） =》值
2）误差分析
假定 误差是独立，同分布，服从均值为0，方差为θ的高斯分布
最大对数似然（预测值是真实值的可能性越大越好，使得预测值与真实值之间的误差越小越好最好,极大似然估计的目标函数和最小平方误差是等价的），化简，得到
目标函数（最后要计算的简单的式子，就是误差平方了，）求偏导极小值点，
随机/批量/小批量（32，64，128）梯度下降，
学习率（步长）（0.01，0.001），
注）：
似然函数为知道了结果求条件，概率问题为知道了条件求概率
3）评估方法
+）衡量标准
用测试数据集衡量
R Square
R² = 1-Σ((y_hat-yi)^2)/Σ((y_bar-yi)^2)
1-预测的错/粗略的错（基准模型）
R²越接近1越好，小于0则可能是数据不存在这种关系，比基准模型还差
MSE 均方误差 Mean Squared Error
(1/m)*Σ（yi-yi_hat)²
RMSE root
√((1/m)*Σ（yi-yi_hat)²)
MAE mean_absolute_error
(1/m)Σ|yi-y_hat|
（能保证量纲一样）
【简单线性回归
只有一个特征
【多元线性回归
【other
最优化原理
凸优化
for xi,yi in zip(x,y):
