【各种学习基本概念】
符号学习
统计机器学习
符号学习指是对符号（词汇，图表等）意义的直接学习理解，比如说分析语法，句法结构什么的；
统计学习则是指对基于大量的数据进行统计分析学习；
独立同分布】
如果这些随机变量服从同一分布，并且互相独立，那么这些随机变量是独立同分布。
迁移学习】
大量旧样本（已标记，有其他类）-》选出有效数据
当前只有少量新的标记的数据，但是有【大量旧的已标记的】数据（甚至是【其他类别的有效数据】），这时通过挑选这些旧数据中的有效的数据，加入到当前的训练数据中，（然后进行监督学习？）训练新的模型。
自我学习】
少量样本（已标记）+大量无标注（自然图片（可包含类外的））
监督学习】分类、回归
监督训练】
教师学习】大量已标注样本
利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的 过程，
监督学习是从标记的训练数据来推断一个功能的机器学习任务。
半监督学习】
少量（已标注）+大量无标注（但属于这两类中）
比如分离大象和犀牛。对于监督学习来说，我们手头有大量大象的样本和犀牛的样本，接下来训练分类器，进行分类，大家都知道的。对于迁移学习，则是指我们手头上有大量羊的样本和马的样本（已标记），少量的大象和犀牛的样本，接下来就要从羊和马的样本中选出有效的样本分别加入到大象和犀牛的标记样本中，然后再用监督学习的方法训练分类器。而半监督学习，则是手上仅有少量大象和犀牛的已标记样本，另外有一堆大象和犀牛的没有标记的数据（注意它们中要么是大象要么是犀牛，没有其他物种）。半监督学习就是利用这些样本训练分类器，实现分类。而自我学习，同样是手上仅有少量大象和犀牛的已标记样本，另外有一大堆自然图像。所谓自然图像，就是有大象和犀牛的图片，还有各种其他物种的图片。自我学习比半监督学习更适合实际场景
深度学习】
深度学习是机器学习中一种【基于对数据进行表征】学习的方法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。
深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。[2] 
同机器学习方法一样，深度机器学习方法也有监督学习与无监督学习之分．不同的学习框架下建立的学习模型很是不同．例如，【卷积神经网络】（Convolutional neural networks，简称CNNs）就是一种深度的监督学习下的机器学习模型，而【深度置信网】（Deep Belief Nets，简称DBNs）就是一种无监督学习下的机器学习模型。
无监督学习】聚类
流形学习】
本质上，流形学习就是给数据降维的过程。这里假设数据是一个随机样本，采样自一个高维欧氏空间中的流形（manifold），流形学习的任务就是把这个高维流形映射到一个低维（例如2维）的空间里。流形学习可以分为线性算法和非线性算法，前者包括主成分分析（PCA）和线性判别分析（LDA），后者包括等距映射（Isomap），拉普拉斯特征映射（LE）等。流形学习可以用于特征的降维和提取，为后续的基于特征的分析，如聚类和分类，做铺垫，也可以直接应用于数据可视化等。
集成学习】
多示例和多标记学习】
类比学习】
典型的方法是K-最近邻方法，它属于懒散学习法，相比决策树等急切学习法，具有训练时间短，但分类时间长的特点。K-最近邻算法可以用于分类和聚类中。
